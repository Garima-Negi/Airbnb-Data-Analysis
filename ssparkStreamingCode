bin/sparkling-shell --conf "spark.executor.memory=1g"
import org.apache.spark.h2o._ val h2oContext = H2OContext.getOrCreate(spark) import h2oContext._
import org.apache.spark._
import org.apache.spark.streaming._
val ssc = new StreamingContext(sc, Seconds(5))
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
val lines = ssc.fileStream[LongWritable, Text, TextInputFormat]("/Users/arjun/Downloads/AirBnb/Test").map{case(k,v) => (k.toString,v.toString.split(“,”).last)}
lines.print
